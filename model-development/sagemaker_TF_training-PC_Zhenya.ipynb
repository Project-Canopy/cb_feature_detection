{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning with Tensorflow on Amazon SageMaker and S3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.32.1\n"
     ]
    }
   ],
   "source": [
    "import sagemaker\n",
    "\n",
    "print(sagemaker.__version__)\n",
    "sess = sagemaker.Session()\n",
    "# role = sagemaker.get_execution_role()\n",
    "import os\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from sagemaker.inputs import FileSystemInput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.4.1'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on the notebook on local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "\n",
    "# put these files in the respective training folder\n",
    "training_file = \"labels_test_v1_m.csv\"\n",
    "validation_file = \"val_labels_m.csv\"\n",
    "\n",
    "tf_estimator = TensorFlow(entry_point='train_no_s3.py', \n",
    "                          role=\"arn:aws:iam::963659202518:role/service-role/AmazonSageMaker-ExecutionRole-20210306T191865\",\n",
    "                          instance_count=1, \n",
    "                          instance_type='local',\n",
    "                          framework_version='2.4.1', \n",
    "                          base_job_name='pc-tf-custom-container-test-job',\n",
    "                          output_path='s3://canopy-production-ml-output',\n",
    "                          py_version='py37',\n",
    "                          script_mode=True,\n",
    "                          hyperparameters={'training_file':training_file, \n",
    "                                           'validation_file': validation_file,\n",
    "#                                            'bucket':\"margaux-bucket-us-east-1\",\n",
    "                                           'epochs': 2, 'augment': True, 'batch-size': 100,\n",
    "                                           'learning-rate': 0.01, 'numclasses': 10,\n",
    "                                           'wandb_key': \"abfa0dec9fc06fbfa6392496f40a22a8d47e58cf\",\n",
    "                                           's3_chkpt_dir':\"ckpt\",\n",
    "                                           'bands': \"2 3 4 8 12\",\n",
    "                                           'starting_checkpoint':\"ckpt/pc-tf-custom-container-test-job-RGBNIRN-2021-03-15-22-45-06-142/model_resnet_epoch_7.h5\"}\n",
    "                         )\n",
    "                                            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating network \"sagemaker-local\" with the default driver\n",
      "Creating g0zhkp446s-algo-1-duwzu ... \n",
      "\u001b[1BAttaching to g0zhkp446s-algo-1-duwzu2mdone\u001b[0m\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m 2021-03-24 02:40:31.880169: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m 2021-03-24 02:40:31.882746: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m 2021-03-24 02:40:31.928211: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m 2021-03-24 02:40:34,195 sagemaker-training-toolkit INFO     Imported framework sagemaker_tensorflow_container.training\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m 2021-03-24 02:40:34,207 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m 2021-03-24 02:40:34,244 botocore.credentials INFO     Found credentials in environment variables.\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m 2021-03-24 02:40:34,649 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m 2021-03-24 02:40:34,675 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m 2021-03-24 02:40:34,702 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m 2021-03-24 02:40:34,718 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m \n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Training Env:\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m \n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m {\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m     \"additional_framework_parameters\": {},\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m     \"channel_input_dirs\": {\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m         \"training\": \"/opt/ml/input/data/training\"\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m     },\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m     \"current_host\": \"algo-1-duwzu\",\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m     \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m     \"hosts\": [\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m         \"algo-1-duwzu\"\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m     ],\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m     \"hyperparameters\": {\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m         \"training_file\": \"labels_test_v1_m.csv\",\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m         \"validation_file\": \"val_labels_m.csv\",\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m         \"epochs\": 2,\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m         \"augment\": true,\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m         \"batch-size\": 100,\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m         \"learning-rate\": 0.01,\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m         \"numclasses\": 10,\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m         \"wandb_key\": \"6607ed7a49b452c2f3494ce60f9514f6c9e3b4e6\",\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m         \"s3_chkpt_dir\": \"ckpt\",\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m         \"bands\": \"2 3 4 8 12\",\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m         \"starting_checkpoint\": \"ckpt/pc-tf-custom-container-test-job-RGBNIRN-2021-03-15-22-45-06-142/model_resnet_epoch_7.h5\",\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m         \"model_dir\": \"s3://canopy-production-ml-output/pc-tf-custom-container-test-job-2021-03-24-02-35-34-108/model\"\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m     },\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m     \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m     \"input_data_config\": {\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m         \"training\": {\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m             \"TrainingInputMode\": \"File\"\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m         }\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m     },\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m     \"input_dir\": \"/opt/ml/input\",\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m     \"is_master\": true,\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m     \"job_name\": \"pc-tf-custom-container-test-job-2021-03-24-02-35-34-108\",\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m     \"log_level\": 20,\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m     \"master_hostname\": \"algo-1-duwzu\",\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m     \"model_dir\": \"/opt/ml/model\",\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m     \"module_dir\": \"s3://canopy-production-ml-output/pc-tf-custom-container-test-job-2021-03-24-02-35-34-108/source/sourcedir.tar.gz\",\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m     \"module_name\": \"train_no_s3\",\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m     \"network_interface_name\": \"eth0\",\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m     \"num_cpus\": 2,\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m     \"num_gpus\": 0,\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m     \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m     \"output_dir\": \"/opt/ml/output\",\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m     \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m     \"resource_config\": {\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m         \"current_host\": \"algo-1-duwzu\",\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m         \"hosts\": [\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m             \"algo-1-duwzu\"\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m         ]\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m     },\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m     \"user_entry_point\": \"train_no_s3.py\"\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m }\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m \n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Environment variables:\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m \n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m SM_HOSTS=[\"algo-1-duwzu\"]\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m SM_NETWORK_INTERFACE_NAME=eth0\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m SM_HPS={\"augment\":true,\"bands\":\"2 3 4 8 12\",\"batch-size\":100,\"epochs\":2,\"learning-rate\":0.01,\"model_dir\":\"s3://canopy-production-ml-output/pc-tf-custom-container-test-job-2021-03-24-02-35-34-108/model\",\"numclasses\":10,\"s3_chkpt_dir\":\"ckpt\",\"starting_checkpoint\":\"ckpt/pc-tf-custom-container-test-job-RGBNIRN-2021-03-15-22-45-06-142/model_resnet_epoch_7.h5\",\"training_file\":\"labels_test_v1_m.csv\",\"validation_file\":\"val_labels_m.csv\",\"wandb_key\":\"6607ed7a49b452c2f3494ce60f9514f6c9e3b4e6\"}\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m SM_USER_ENTRY_POINT=train_no_s3.py\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m SM_FRAMEWORK_PARAMS={}\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m SM_RESOURCE_CONFIG={\"current_host\":\"algo-1-duwzu\",\"hosts\":[\"algo-1-duwzu\"]}\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m SM_INPUT_DATA_CONFIG={\"training\":{\"TrainingInputMode\":\"File\"}}\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m SM_OUTPUT_DATA_DIR=/opt/ml/output/data\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m SM_CHANNELS=[\"training\"]\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m SM_CURRENT_HOST=algo-1-duwzu\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m SM_MODULE_NAME=train_no_s3\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m SM_LOG_LEVEL=20\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m SM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m SM_INPUT_DIR=/opt/ml/input\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m SM_INPUT_CONFIG_DIR=/opt/ml/input/config\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m SM_OUTPUT_DIR=/opt/ml/output\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m SM_NUM_CPUS=2\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m SM_NUM_GPUS=0\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m SM_MODEL_DIR=/opt/ml/model\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m SM_MODULE_DIR=s3://canopy-production-ml-output/pc-tf-custom-container-test-job-2021-03-24-02-35-34-108/source/sourcedir.tar.gz\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m SM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1-duwzu\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1-duwzu\"],\"hyperparameters\":{\"augment\":true,\"bands\":\"2 3 4 8 12\",\"batch-size\":100,\"epochs\":2,\"learning-rate\":0.01,\"model_dir\":\"s3://canopy-production-ml-output/pc-tf-custom-container-test-job-2021-03-24-02-35-34-108/model\",\"numclasses\":10,\"s3_chkpt_dir\":\"ckpt\",\"starting_checkpoint\":\"ckpt/pc-tf-custom-container-test-job-RGBNIRN-2021-03-15-22-45-06-142/model_resnet_epoch_7.h5\",\"training_file\":\"labels_test_v1_m.csv\",\"validation_file\":\"val_labels_m.csv\",\"wandb_key\":\"6607ed7a49b452c2f3494ce60f9514f6c9e3b4e6\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pc-tf-custom-container-test-job-2021-03-24-02-35-34-108\",\"log_level\":20,\"master_hostname\":\"algo-1-duwzu\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://canopy-production-ml-output/pc-tf-custom-container-test-job-2021-03-24-02-35-34-108/source/sourcedir.tar.gz\",\"module_name\":\"train_no_s3\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1-duwzu\",\"hosts\":[\"algo-1-duwzu\"]},\"user_entry_point\":\"train_no_s3.py\"}\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m SM_USER_ARGS=[\"--augment\",\"True\",\"--bands\",\"2 3 4 8 12\",\"--batch-size\",\"100\",\"--epochs\",\"2\",\"--learning-rate\",\"0.01\",\"--model_dir\",\"s3://canopy-production-ml-output/pc-tf-custom-container-test-job-2021-03-24-02-35-34-108/model\",\"--numclasses\",\"10\",\"--s3_chkpt_dir\",\"ckpt\",\"--starting_checkpoint\",\"ckpt/pc-tf-custom-container-test-job-RGBNIRN-2021-03-15-22-45-06-142/model_resnet_epoch_7.h5\",\"--training_file\",\"labels_test_v1_m.csv\",\"--validation_file\",\"val_labels_m.csv\",\"--wandb_key\",\"6607ed7a49b452c2f3494ce60f9514f6c9e3b4e6\"]\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m SM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m SM_CHANNEL_TRAINING=/opt/ml/input/data/training\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m SM_HP_TRAINING_FILE=labels_test_v1_m.csv\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m SM_HP_VALIDATION_FILE=val_labels_m.csv\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m SM_HP_EPOCHS=2\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m SM_HP_AUGMENT=true\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m SM_HP_BATCH-SIZE=100\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m SM_HP_LEARNING-RATE=0.01\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m SM_HP_NUMCLASSES=10\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m SM_HP_WANDB_KEY=6607ed7a49b452c2f3494ce60f9514f6c9e3b4e6\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m SM_HP_S3_CHKPT_DIR=ckpt\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m SM_HP_BANDS=2 3 4 8 12\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m SM_HP_STARTING_CHECKPOINT=ckpt/pc-tf-custom-container-test-job-RGBNIRN-2021-03-15-22-45-06-142/model_resnet_epoch_7.h5\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m SM_HP_MODEL_DIR=s3://canopy-production-ml-output/pc-tf-custom-container-test-job-2021-03-24-02-35-34-108/model\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m PYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python37.zip:/usr/local/lib/python3.7:/usr/local/lib/python3.7/lib-dynload:/usr/local/lib/python3.7/site-packages\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m \n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Invoking script with the following command:\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m \n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m /usr/local/bin/python3.7 train_no_s3.py --augment True --bands 2 3 4 8 12 --batch-size 100 --epochs 2 --learning-rate 0.01 --model_dir s3://canopy-production-ml-output/pc-tf-custom-container-test-job-2021-03-24-02-35-34-108/model --numclasses 10 --s3_chkpt_dir ckpt --starting_checkpoint ckpt/pc-tf-custom-container-test-job-RGBNIRN-2021-03-15-22-45-06-142/model_resnet_epoch_7.h5 --training_file labels_test_v1_m.csv --validation_file val_labels_m.csv --wandb_key 6607ed7a49b452c2f3494ce60f9514f6c9e3b4e6\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m \n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m \n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Num GPUs Available:  0\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m TensorFlow version 2.4.1\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Keras version 2.4.0\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Collecting keras-metrics\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m   Downloading keras_metrics-1.1.0-py2.py3-none-any.whl (5.6 kB)\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Collecting Keras>=2.1.5\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m   Downloading Keras-2.4.3-py2.py3-none-any.whl (36 kB)\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/site-packages (from Keras>=2.1.5->keras-metrics) (5.4.1)\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Requirement already satisfied: h5py in /usr/local/lib/python3.7/site-packages (from Keras>=2.1.5->keras-metrics) (2.10.0)\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/site-packages (from Keras>=2.1.5->keras-metrics) (1.19.5)\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/site-packages (from Keras>=2.1.5->keras-metrics) (1.5.2)\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Requirement already satisfied: six in /usr/local/lib/python3.7/site-packages (from h5py->Keras>=2.1.5->keras-metrics) (1.15.0)\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Installing collected packages: Keras, keras-metrics\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Successfully installed Keras-2.4.3 keras-metrics-1.1.0\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Collecting tensorflow-addons\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m   Downloading tensorflow_addons-0.12.1-cp37-cp37m-manylinux2010_x86_64.whl (703 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 703 kB 5.1 MB/s eta 0:00:01\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m \u001b[?25hCollecting typeguard>=2.7\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m   Downloading typeguard-2.11.1-py3-none-any.whl (16 kB)\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Installing collected packages: typeguard, tensorflow-addons\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Successfully installed tensorflow-addons-0.12.1 typeguard-2.11.1\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Collecting wandb\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m   Downloading wandb-0.10.23-py2.py3-none-any.whl (2.0 MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.0 MB 3.4 MB/s eta 0:00:01\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m \u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/site-packages (from wandb) (2.24.0)\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Collecting configparser>=3.8.1\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m   Downloading configparser-5.0.2-py3-none-any.whl (19 kB)\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Collecting GitPython>=1.0.0\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m   Downloading GitPython-3.1.14-py3-none-any.whl (159 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 159 kB 19.2 MB/s eta 0:00:01\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m \u001b[?25hCollecting sentry-sdk>=0.4.0\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m   Downloading sentry_sdk-1.0.0-py2.py3-none-any.whl (131 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 131 kB 13.4 MB/s eta 0:00:01\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m \u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/site-packages (from wandb) (5.4.1)\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Collecting promise<3,>=2.0\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m   Downloading promise-2.3.tar.gz (19 kB)\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/site-packages (from wandb) (1.15.0)\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/site-packages (from wandb) (3.15.6)\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/site-packages (from wandb) (2.8.1)\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Collecting shortuuid>=0.5.0\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m   Downloading shortuuid-1.0.1-py3-none-any.whl (7.5 kB)\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Collecting docker-pycreds>=0.4.0\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m   Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Collecting pathtools\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m   Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Collecting Click>=7.0\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m   Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 82 kB 1.5 MB/s  eta 0:00:01\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m \u001b[?25hCollecting subprocess32>=3.5.3\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m   Downloading subprocess32-3.5.4.tar.gz (97 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 97 kB 7.9 MB/s  eta 0:00:01\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m \u001b[?25hRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/site-packages (from wandb) (5.7.2)\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Collecting gitdb<5,>=4.0.1\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m   Downloading gitdb-4.0.5-py3-none-any.whl (63 kB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 63 kB 2.4 MB/s  eta 0:00:01\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m \u001b[?25hCollecting smmap<4,>=3.0.1\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m   Downloading smmap-3.0.5-py2.py3-none-any.whl (25 kB)\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.25.11)\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2020.12.5)\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.10)\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Building wheels for collected packages: promise, subprocess32, pathtools\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m   Building wheel for promise (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m \u001b[?25h  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21494 sha256=c67fb99e5e2a5ea2ac6195dc0a17b42d115a052158eb4ddeda03ae1548d135d3\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m   Stored in directory: /root/.cache/pip/wheels/29/93/c6/762e359f8cb6a5b69c72235d798804cae523bbe41c2aa8333d\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m   Building wheel for subprocess32 (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m \u001b[?25h  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6488 sha256=d00542f98c515a0adca41c3eb95631f1533828beb7f20b06442f767dbf984440\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m   Stored in directory: /root/.cache/pip/wheels/50/ca/fa/8fca8d246e64f19488d07567547ddec8eb084e8c0d7a59226a\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m   Building wheel for pathtools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m \u001b[?25h  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8784 sha256=7f80f619687931098be1490fd6e5efc937e318b04d0080e5d50c4c91ef1de871\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m   Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Successfully built promise subprocess32 pathtools\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Installing collected packages: smmap, gitdb, subprocess32, shortuuid, sentry-sdk, promise, pathtools, GitPython, docker-pycreds, configparser, Click, wandb\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Successfully installed Click-7.1.2 GitPython-3.1.14 configparser-5.0.2 docker-pycreds-0.4.0 gitdb-4.0.5 pathtools-0.1.2 promise-2.3 sentry-sdk-1.0.0 shortuuid-1.0.1 smmap-3.0.5 subprocess32-3.5.4 wandb-0.10.23\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Collecting rasterio\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m   Downloading rasterio-1.2.1-cp37-cp37m-manylinux1_x86_64.whl (19.1 MB)\n",
      "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 19.1 MB 11.1 MB/s eta 0:00:01\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m \u001b[?25hCollecting affine\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m   Downloading affine-2.3.0-py2.py3-none-any.whl (15 kB)\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Requirement already satisfied: attrs in /usr/local/lib/python3.7/site-packages (from rasterio) (20.3.0)\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Collecting snuggs>=1.4.1\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m   Downloading snuggs-1.4.7-py3-none-any.whl (5.4 kB)\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Requirement already satisfied: certifi in /usr/local/lib/python3.7/site-packages (from rasterio) (2020.12.5)\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Collecting click-plugins\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m   Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Requirement already satisfied: click<8,>=4.0 in /usr/local/lib/python3.7/site-packages (from rasterio) (7.1.2)\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Requirement already satisfied: numpy in /usr/local/lib/python3.7/site-packages (from rasterio) (1.19.5)\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Collecting cligj>=0.5\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m   Downloading cligj-0.7.1-py3-none-any.whl (7.1 kB)\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Requirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.7/site-packages (from snuggs>=1.4.1->rasterio) (2.4.7)\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Installing collected packages: snuggs, cligj, click-plugins, affine, rasterio\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Successfully installed affine-2.3.0 click-plugins-1.1.1 cligj-0.7.1 rasterio-1.2.1 snuggs-1.4.7\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Requirement already satisfied: boto3 in /usr/local/lib/python3.7/site-packages (1.17.33)\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/site-packages (from boto3) (0.10.0)\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Requirement already satisfied: botocore<1.21.0,>=1.20.33 in /usr/local/lib/python3.7/site-packages (from boto3) (1.20.33)\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/site-packages (from boto3) (0.3.6)\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/site-packages (from botocore<1.21.0,>=1.20.33->boto3) (2.8.1)\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Requirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/site-packages (from botocore<1.21.0,>=1.20.33->boto3) (1.25.11)\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.33->boto3) (1.15.0)\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m \n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Starting checkpoint: ckpt/pc-tf-custom-container-test-job-RGBNIRN-2021-03-15-22-45-06-142/model_resnet_epoch_7.h5\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m lr: 0.01, batch_size: 100, augmentation_data: True\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m bands [2, 3, 4, 8, 12]\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Input shape: (100, 100, 5)\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m [2021-03-24 02:40:59.631 d34fe9388d12:21 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m [2021-03-24 02:40:59.748 d34fe9388d12:21 INFO profiler_config_parser.py:102] Unable to find config at /opt/ml/input/config/profilerconfig.json. Profiler is disabled.\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "94773248/94765736 [==============================] - 4s 0us/step\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m No previous checkpoint found in opt/ml/checkpoints directory; loading checkpoint from ckpt/pc-tf-custom-container-test-job-RGBNIRN-2021-03-15-22-45-06-142/model_resnet_epoch_7.h5\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m training_dir /opt/ml/input/data/training/labels_test_v1_m.csv\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m val_dir /opt/ml/input/data/training/val_labels_m.csv\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Dataloader initialization...\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m label_file_path_train: /opt/ml/input/data/training/labels_test_v1_m.csv\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m labels_file_val: /opt/ml/input/data/training/val_labels_m.csv\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Data augmentation enabled\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Training on 300 images\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Validation on 3 images \n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Epoch 1/2\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m 2021-03-24 02:40:34.900380: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m 2021-03-24 02:40:34.902079: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m 2021-03-24 02:40:34.946036: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m wandb: Currently logged in as: margauxmforsythe (use `wandb login --relogin` to force relogin)\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m 2021-03-24 02:40:57.351089: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m 2021-03-24 02:40:57.352925: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m 2021-03-24 02:40:57.403407: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m wandb: Tracking run with wandb version 0.10.23\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m wandb: Syncing run pc-tf-custom-container-test-job-2021-03-24-02-35-34-108-algo-1-duwzu\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m wandb: â­ï¸ View project at https://wandb.ai/margauxmforsythe/project-canopy\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m wandb: ðŸš€ View run at https://wandb.ai/margauxmforsythe/project-canopy/runs/pc-tf-custom-container-test-job-2021-03-24-02-35-34-108-algo-1-duwzu\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m wandb: Run data is saved locally in /opt/ml/code/wandb/run-20210324_024056-pc-tf-custom-container-test-job-2021-03-24-02-35-34-108-algo-1-duwzu\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m INFO:botocore.credentials:Found credentials in environment variables.\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m \n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m 2021-03-24 02:42:21,890 sagemaker-training-toolkit ERROR    ExecuteUserScriptError:\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m Command \"/usr/local/bin/python3.7 train_no_s3.py --augment True --bands 2 3 4 8 12 --batch-size 100 --epochs 2 --learning-rate 0.01 --model_dir s3://canopy-production-ml-output/pc-tf-custom-container-test-job-2021-03-24-02-35-34-108/model --numclasses 10 --s3_chkpt_dir ckpt --starting_checkpoint ckpt/pc-tf-custom-container-test-job-RGBNIRN-2021-03-15-22-45-06-142/model_resnet_epoch_7.h5 --training_file labels_test_v1_m.csv --validation_file val_labels_m.csv --wandb_key 6607ed7a49b452c2f3494ce60f9514f6c9e3b4e6\"\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m 2021-03-24 02:40:34.900380: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m 2021-03-24 02:40:34.902079: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m 2021-03-24 02:40:34.946036: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m wandb: Currently logged in as: margauxmforsythe (use `wandb login --relogin` to force relogin)\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m 2021-03-24 02:40:57.351089: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m 2021-03-24 02:40:57.352925: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m 2021-03-24 02:40:57.403407: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m wandb: Tracking run with wandb version 0.10.23\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m wandb: Syncing run pc-tf-custom-container-test-job-2021-03-24-02-35-34-108-algo-1-duwzu\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m wandb: Ã¢Â­ÂÃ¯Â¸Â View project at https://wandb.ai/margauxmforsythe/project-canopy\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m wandb: Ã°ÂŸÂšÂ€ View run at https://wandb.ai/margauxmforsythe/project-canopy/runs/pc-tf-custom-container-test-job-2021-03-24-02-35-34-108-algo-1-duwzu\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m wandb: Run data is saved locally in /opt/ml/code/wandb/run-20210324_024056-pc-tf-custom-container-test-job-2021-03-24-02-35-34-108-algo-1-duwzu\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m wandb: Run `wandb offline` to turn off syncing.\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu |\u001b[0m INFO:botocore.credentials:Found credentials in environment variables.\n",
      "\u001b[36mg0zhkp446s-algo-1-duwzu exited with code 1\n",
      "\u001b[0mAborting on container exit...\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to run: ['docker-compose', '-f', '/private/var/folders/cz/s5n0rss95_d_fkgnjz19kgbr0000gn/T/tmpfdyykckx/docker-compose.yaml', 'up', '--build', '--abort-on-container-exit'], Process exited with code: 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/envs/ml-conda/lib/python3.7/site-packages/sagemaker/local/image.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_data_config, output_data_config, hyperparameters, job_name)\u001b[0m\n\u001b[1;32m    237\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 238\u001b[0;31m             \u001b[0m_stream_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    239\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mRuntimeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ml-conda/lib/python3.7/site-packages/sagemaker/local/image.py\u001b[0m in \u001b[0;36m_stream_output\u001b[0;34m(process)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexit_code\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 894\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Process exited with code: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mexit_code\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    895\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Process exited with code: 1",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-85c093f1e0cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtf_estimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"file:///Users/purgatorid/Documents/GitHub/Project Canopy/cb_feature_detection/model-development/data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mt0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m60\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ml-conda/lib/python3.7/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, inputs, wait, logs, job_name, experiment_config)\u001b[0m\n\u001b[1;32m    659\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prepare_for_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_TrainingJob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlatest_training_job\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ml-conda/lib/python3.7/site-packages/sagemaker/estimator.py\u001b[0m in \u001b[0;36mstart_new\u001b[0;34m(cls, estimator, inputs, experiment_config)\u001b[0m\n\u001b[1;32m   1422\u001b[0m         \"\"\"\n\u001b[1;32m   1423\u001b[0m         \u001b[0mtrain_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_train_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexperiment_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1424\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrain_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1425\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1426\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_job_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ml-conda/lib/python3.7/site-packages/sagemaker/session.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_mode, input_config, role, job_name, output_config, resource_config, vpc_config, hyperparameters, stop_condition, tags, metric_definitions, enable_network_isolation, image_uri, algorithm_arn, encrypt_inter_container_traffic, use_spot_instances, checkpoint_s3_uri, checkpoint_local_path, experiment_config, debugger_rule_configs, debugger_hook_config, tensorboard_output_config, enable_sagemaker_metrics, profiler_rule_configs, profiler_config)\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Creating training-job with name: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m         \u001b[0mLOGGER\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"train request: %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_request\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msagemaker_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_training_job\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mtrain_request\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m     def _get_train_request(  # noqa: C901\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ml-conda/lib/python3.7/site-packages/sagemaker/local/local_session.py\u001b[0m in \u001b[0;36mcreate_training_job\u001b[0;34m(self, TrainingJobName, AlgorithmSpecification, OutputDataConfig, ResourceConfig, InputDataConfig, **kwargs)\u001b[0m\n\u001b[1;32m    184\u001b[0m         \u001b[0mhyperparameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"HyperParameters\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m\"HyperParameters\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Starting training job\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 186\u001b[0;31m         \u001b[0mtraining_job\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInputDataConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mOutputDataConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTrainingJobName\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0mLocalSagemakerClient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_training_jobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTrainingJobName\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_job\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ml-conda/lib/python3.7/site-packages/sagemaker/local/entities.py\u001b[0m in \u001b[0;36mstart\u001b[0;34m(self, input_data_config, output_data_config, hyperparameters, job_name)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m         self.model_artifacts = self.container.train(\n\u001b[0;32m--> 221\u001b[0;31m             \u001b[0minput_data_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_data_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m         )\n\u001b[1;32m    223\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/ml-conda/lib/python3.7/site-packages/sagemaker/local/image.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_data_config, output_data_config, hyperparameters, job_name)\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;31m# which contains the exit code and append the command line to it.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Failed to run: %s, %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcompose_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 243\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    244\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    245\u001b[0m             \u001b[0martifacts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve_artifacts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompose_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_data_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjob_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Failed to run: ['docker-compose', '-f', '/private/var/folders/cz/s5n0rss95_d_fkgnjz19kgbr0000gn/T/tmpfdyykckx/docker-compose.yaml', 'up', '--build', '--abort-on-container-exit'], Process exited with code: 1"
     ]
    }
   ],
   "source": [
    "import time\n",
    "t0 = time.time()\n",
    "tf_estimator.fit(\"file:///Users/purgatorid/Documents/GitHub/Project Canopy/cb_feature_detection/model-development/data\")\n",
    "t1 = time.time()\n",
    "total = (t1-t0) / 60\n",
    "print(f\"{total} min\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on Cloud Amazon SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_max_run has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_use_spot_instances has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_max_wait has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.tensorflow import TensorFlow\n",
    "from sagemaker.debugger import Rule, rule_configs\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "training_file = \"labels_train.csv\"\n",
    "validation_file = \"labels_val.csv\"\n",
    "tf_estimator = TensorFlow(entry_point='train_no_s3.py', \n",
    "                          role=\"arn:aws:iam::963659202518:role/service-role/AmazonSageMaker-ExecutionRole-20210306T191865\",\n",
    "                          #                           role=get_execution_role(),\n",
    "                          train_instance_count=1, \n",
    "                          train_instance_type='ml.p3.2xlarge', # ml.m5.large, ml.p3.16xlarge, ml.p3.2xlarge, ml.g4dn.xlarge, ml.p3.8xlarge, p3.2xlarge, ml.t2.micro\n",
    "                          framework_version='2.4', \n",
    "                          base_job_name='pc-tf-custom-container-test-job-RGBNIRN',\n",
    "                          output_path='s3://canopy-production-ml-output',\n",
    "                          py_version='py37',\n",
    "                          checkpoint_s3_uri=\"s3://canopy-production-ml-output/ckpt/pc-tf-custom-container-test-job-RGBNIRN\",\n",
    "                          script_mode=True,\n",
    "                          train_use_spot_instances=True,        # Use spot instance\n",
    "                          train_max_run=432000,                    # Max training time\n",
    "                          train_max_wait=450000,                  # Max training time + spot waiting time\n",
    "                          hyperparameters={'training_file':training_file, \n",
    "                                           'validation_file': validation_file,\n",
    "#                                            'bucket':\"margaux-bucket-us-east-1\",\n",
    "                                           'epochs': 5, 'augment': True, 'batch-size': 100,\n",
    "                                           'learning-rate': 0.001, 'numclasses': 10,\n",
    "                                           'wandb_key': \"6607ed7a49b452c2f3494ce60f9514f6c9e3b4e6\",\n",
    "                                           's3_chkpt_dir':\"ckpt\",\n",
    "                                           'bands': \"2 3 4 8 12\",\n",
    "                                          'starting_checkpoint':None\n",
    "                                          }\n",
    "                         )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "'create_image_uri' will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-03-22 22:33:23 Starting - Starting the training job...\n",
      "2021-03-22 22:33:24 Starting - Launching requested ML instances.........\n",
      "2021-03-22 22:35:05 Starting - Preparing the instances for training...\n",
      "2021-03-22 22:35:53 Downloading - Downloading input data."
     ]
    }
   ],
   "source": [
    "tf_estimator.fit(\"s3://canopy-production-ml/chips/cloudfree-merge-polygons/split/\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FSX Input Obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old_dataset_directory = '/h4zifbmv/chips/cloudfree-merge-polygons/split'\n",
    "new_dataset_directory = '/h4zifbmv/chips/cloudfree-merge-polygons/dataset_v2'\n",
    "\n",
    "\n",
    "fsx_data_obj = FileSystemInput(file_system_id='fs-03cd4325554338c21',\n",
    "                                    file_system_type='FSxLustre',\n",
    "                                    directory_path=new_dataset_directory,\n",
    "                                    file_system_access_mode='ro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EFS Input Obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old_dataset_directory = '/h4zifbmv/chips/cloudfree-merge-polygons/split'\n",
    "new_dataset_directory = \"/\"\n",
    "\n",
    "\n",
    "efs_data_obj = FileSystemInput(file_system_id='fs-f1777e44',\n",
    "                                    file_system_type='EFS',\n",
    "                                    directory_path=new_dataset_directory,\n",
    "                                    file_system_access_mode='ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO : LR update - min .0001 vs .00001, Data Aug - Enable \"flip_left_right\" \n",
    "\n",
    "\n",
    "\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "from sagemaker.debugger import Rule, rule_configs\n",
    "from sagemaker import get_execution_role\n",
    "import time\n",
    "\n",
    "job_name = 'pc-tf-custom-container-test-job-RGBNIRSWIR1SWIR2'\n",
    "\n",
    "\n",
    "# old_training_file = \"labels_full_train_v6.csv\"\n",
    "# old_validation_file = \"labels_val.csv\"\n",
    "# new_training_file = \"new_train_labels_v5_10_percent.csv\"\n",
    "# new_training_file = \"new_train_labels_v7_one_quarter.csv\"\n",
    "new_training_file = \"new_train_labels_v7_one_quarter.csv\"\n",
    "new_validation_file = \"new_val_labels_v3.csv\"\n",
    "# old_band_combo = [2,3,4,8,12]\n",
    "# band_rgbnir = [2,3,4,8,18]\n",
    "# bands_all = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 16, 17, 18]\n",
    "\n",
    "\n",
    "tf_estimator = TensorFlow(entry_point='train_no_s3.py', \n",
    "                          role=\"arn:aws:iam::963659202518:role/service-role/AmazonSageMaker-ExecutionRole-20210306T191865\",\n",
    "                          #                           role=get_execution_role(),\n",
    "                          instance_count=1, \n",
    "                          instance_type='ml.g4dn.4xlarge', # ml.m5.large, ml.p3.16xlarge, ml.p3.2xlarge, ml.g4dn.xlarge, ml.p3.8xlarge, p3.2xlarge, ml.t2.micro\n",
    "                          framework_version='2.4', \n",
    "                          base_job_name=job_name,\n",
    "                          output_path='s3://canopy-production-ml-output',\n",
    "                          py_version='py37',\n",
    "                          checkpoint_s3_uri=f's3://canopy-production-ml-output/ckpt/{job_name}-{time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())}',\n",
    "                          script_mode=True,\n",
    "                          use_spot_instances=True,        # Use spot instance\n",
    "                          max_run=432000,                    # Max training time\n",
    "                          max_wait=450000,                  # Max training time + spot waiting time\n",
    "                            subnets=[\"subnet-815befde\"],\n",
    "                              security_group_ids=[\"sg-0df3ac3b4c291c080\"],\n",
    "                          hyperparameters={'training_file':new_training_file, \n",
    "                                           'validation_file': new_validation_file,\n",
    "#                                            'bucket':\"margaux-bucket-us-east-1\",\n",
    "                                           'epochs': 200, 'augment': False, 'batch-size': 64,\n",
    "                                           'learning-rate': 0.001, 'numclasses': 5,\n",
    "                                           'wandb_key': \"abfa0dec9fc06fbfa6392496f40a22a8d47e58cf\",\n",
    "                                           's3_chkpt_dir':\"ckpt\",\n",
    "                                           'bands': \"2 3 4 8 11 12 18\",\n",
    "                                          'starting_checkpoint':None, \n",
    "                                           'freeze_bn_layer':False\n",
    "                                          }\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-04-08 19:20:55 Starting - Starting the training job...\n",
      "2021-04-08 19:21:19 Starting - Launching requested ML instancesProfilerReport-1617909654: InProgress\n",
      ".........\n",
      "2021-04-08 19:22:39 Starting - Preparing the instances for training......\n",
      "2021-04-08 19:23:59 Downloading - Downloading input data\n",
      "2021-04-08 19:23:59 Training - Downloading the training image............\n",
      "2021-04-08 19:26:00 Training - Training image download completed. Training in progress.\u001b[34m2021-04-08 19:25:50.520833: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2021-04-08 19:25:50.525507: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:105] SageMaker Profiler is not enabled. The timeline writer thread will not be started, future recorded events will be dropped.\u001b[0m\n",
      "\u001b[34m2021-04-08 19:25:50.616182: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\u001b[0m\n",
      "\u001b[34m2021-04-08 19:25:50.702849: W tensorflow/core/profiler/internal/smprofiler_timeline.cc:460] Initializing the SageMaker Profiler.\u001b[0m\n",
      "\u001b[34m2021-04-08 19:25:54,110 sagemaker-training-toolkit INFO     Imported framework sagemaker_tensorflow_container.training\u001b[0m\n",
      "\u001b[34m2021-04-08 19:25:54,642 sagemaker-training-toolkit INFO     Invoking user script\n",
      "\u001b[0m\n",
      "\u001b[34mTraining Env:\n",
      "\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_tensorflow_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"starting_checkpoint\": null,\n",
      "        \"training_file\": \"new_train_labels_v7_one_quarter.csv\",\n",
      "        \"wandb_key\": \"abfa0dec9fc06fbfa6392496f40a22a8d47e58cf\",\n",
      "        \"validation_file\": \"new_val_labels_v3.csv\",\n",
      "        \"bands\": \"2 3 4 8 11 12 18\",\n",
      "        \"s3_chkpt_dir\": \"ckpt\",\n",
      "        \"augment\": false,\n",
      "        \"batch-size\": 64,\n",
      "        \"learning-rate\": 0.001,\n",
      "        \"freeze_bn_layer\": false,\n",
      "        \"numclasses\": 5,\n",
      "        \"model_dir\": \"s3://canopy-production-ml-output/pc-tf-custom-container-test-job-RGBNIRS-2021-04-08-19-12-55-097/model\",\n",
      "        \"epochs\": 200\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"pc-tf-custom-container-test-job-RGBNIRS-2021-04-08-19-20-54-996\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://canopy-production-ml-output/pc-tf-custom-container-test-job-RGBNIRS-2021-04-08-19-20-54-996/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train_no_s3\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 16,\n",
      "    \"num_gpus\": 1,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train_no_s3.py\"\u001b[0m\n",
      "\u001b[34m}\n",
      "\u001b[0m\n",
      "\u001b[34mEnvironment variables:\n",
      "\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"augment\":false,\"bands\":\"2 3 4 8 11 12 18\",\"batch-size\":64,\"epochs\":200,\"freeze_bn_layer\":false,\"learning-rate\":0.001,\"model_dir\":\"s3://canopy-production-ml-output/pc-tf-custom-container-test-job-RGBNIRS-2021-04-08-19-12-55-097/model\",\"numclasses\":5,\"s3_chkpt_dir\":\"ckpt\",\"starting_checkpoint\":null,\"training_file\":\"new_train_labels_v7_one_quarter.csv\",\"validation_file\":\"new_val_labels_v3.csv\",\"wandb_key\":\"abfa0dec9fc06fbfa6392496f40a22a8d47e58cf\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train_no_s3.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train_no_s3\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_tensorflow_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=16\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=1\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://canopy-production-ml-output/pc-tf-custom-container-test-job-RGBNIRS-2021-04-08-19-20-54-996/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_tensorflow_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"augment\":false,\"bands\":\"2 3 4 8 11 12 18\",\"batch-size\":64,\"epochs\":200,\"freeze_bn_layer\":false,\"learning-rate\":0.001,\"model_dir\":\"s3://canopy-production-ml-output/pc-tf-custom-container-test-job-RGBNIRS-2021-04-08-19-12-55-097/model\",\"numclasses\":5,\"s3_chkpt_dir\":\"ckpt\",\"starting_checkpoint\":null,\"training_file\":\"new_train_labels_v7_one_quarter.csv\",\"validation_file\":\"new_val_labels_v3.csv\",\"wandb_key\":\"abfa0dec9fc06fbfa6392496f40a22a8d47e58cf\"},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"pc-tf-custom-container-test-job-RGBNIRS-2021-04-08-19-20-54-996\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://canopy-production-ml-output/pc-tf-custom-container-test-job-RGBNIRS-2021-04-08-19-20-54-996/source/sourcedir.tar.gz\",\"module_name\":\"train_no_s3\",\"network_interface_name\":\"eth0\",\"num_cpus\":16,\"num_gpus\":1,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train_no_s3.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--augment\",\"False\",\"--bands\",\"2 3 4 8 11 12 18\",\"--batch-size\",\"64\",\"--epochs\",\"200\",\"--freeze_bn_layer\",\"False\",\"--learning-rate\",\"0.001\",\"--model_dir\",\"s3://canopy-production-ml-output/pc-tf-custom-container-test-job-RGBNIRS-2021-04-08-19-12-55-097/model\",\"--numclasses\",\"5\",\"--s3_chkpt_dir\",\"ckpt\",\"--starting_checkpoint\",\"\",\"--training_file\",\"new_train_labels_v7_one_quarter.csv\",\"--validation_file\",\"new_val_labels_v3.csv\",\"--wandb_key\",\"abfa0dec9fc06fbfa6392496f40a22a8d47e58cf\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_STARTING_CHECKPOINT=\u001b[0m\n",
      "\u001b[34mSM_HP_TRAINING_FILE=new_train_labels_v7_one_quarter.csv\u001b[0m\n",
      "\u001b[34mSM_HP_WANDB_KEY=abfa0dec9fc06fbfa6392496f40a22a8d47e58cf\u001b[0m\n",
      "\u001b[34mSM_HP_VALIDATION_FILE=new_val_labels_v3.csv\u001b[0m\n",
      "\u001b[34mSM_HP_BANDS=2 3 4 8 11 12 18\u001b[0m\n",
      "\u001b[34mSM_HP_S3_CHKPT_DIR=ckpt\u001b[0m\n",
      "\u001b[34mSM_HP_AUGMENT=false\u001b[0m\n",
      "\u001b[34mSM_HP_BATCH-SIZE=64\u001b[0m\n",
      "\u001b[34mSM_HP_LEARNING-RATE=0.001\u001b[0m\n",
      "\u001b[34mSM_HP_FREEZE_BN_LAYER=false\u001b[0m\n",
      "\u001b[34mSM_HP_NUMCLASSES=5\u001b[0m\n",
      "\u001b[34mSM_HP_MODEL_DIR=s3://canopy-production-ml-output/pc-tf-custom-container-test-job-RGBNIRS-2021-04-08-19-12-55-097/model\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=200\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/opt/ml/code:/usr/local/bin:/usr/local/lib/python37.zip:/usr/local/lib/python3.7:/usr/local/lib/python3.7/lib-dynload:/usr/local/lib/python3.7/site-packages\n",
      "\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\n",
      "\u001b[0m\n",
      "\u001b[34m/usr/local/bin/python3.7 train_no_s3.py --augment False --bands 2 3 4 8 11 12 18 --batch-size 64 --epochs 200 --freeze_bn_layer False --learning-rate 0.001 --model_dir s3://canopy-production-ml-output/pc-tf-custom-container-test-job-RGBNIRS-2021-04-08-19-12-55-097/model --numclasses 5 --s3_chkpt_dir ckpt --starting_checkpoint  --training_file new_train_labels_v7_one_quarter.csv --validation_file new_val_labels_v3.csv --wandb_key abfa0dec9fc06fbfa6392496f40a22a8d47e58cf\n",
      "\n",
      "\u001b[0m\n",
      "\u001b[34mNum GPUs Available:  1\u001b[0m\n",
      "\u001b[34mTensorFlow version 2.4.1\u001b[0m\n",
      "\u001b[34mKeras version 2.4.0\u001b[0m\n",
      "\u001b[34mCollecting keras-metrics\n",
      "  Downloading keras_metrics-1.1.0-py2.py3-none-any.whl (5.6 kB)\u001b[0m\n",
      "\u001b[34mCollecting Keras>=2.1.5\n",
      "  Downloading Keras-2.4.3-py2.py3-none-any.whl (36 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.7/site-packages (from Keras>=2.1.5->keras-metrics) (1.19.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.7/site-packages (from Keras>=2.1.5->keras-metrics) (1.5.2)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyyaml in /usr/local/lib/python3.7/site-packages (from Keras>=2.1.5->keras-metrics) (5.4.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: h5py in /usr/local/lib/python3.7/site-packages (from Keras>=2.1.5->keras-metrics) (2.10.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six in /usr/local/lib/python3.7/site-packages (from h5py->Keras>=2.1.5->keras-metrics) (1.15.0)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: Keras, keras-metrics\u001b[0m\n",
      "\u001b[34mSuccessfully installed Keras-2.4.3 keras-metrics-1.1.0\u001b[0m\n",
      "\u001b[34mCollecting tensorflow-addons\n",
      "  Downloading tensorflow_addons-0.12.1-cp37-cp37m-manylinux2010_x86_64.whl (703 kB)\u001b[0m\n",
      "\u001b[34mCollecting typeguard>=2.7\u001b[0m\n",
      "\u001b[34m  Downloading typeguard-2.12.0-py3-none-any.whl (16 kB)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: typeguard, tensorflow-addons\u001b[0m\n",
      "\u001b[34mSuccessfully installed tensorflow-addons-0.12.1 typeguard-2.12.0\u001b[0m\n",
      "\u001b[34mCollecting wandb\n",
      "  Downloading wandb-0.10.25-py2.py3-none-any.whl (2.1 MB)\u001b[0m\n",
      "\u001b[34mCollecting sentry-sdk>=0.4.0\n",
      "  Downloading sentry_sdk-1.0.0-py2.py3-none-any.whl (131 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.7/site-packages (from wandb) (2.24.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.7/site-packages (from wandb) (3.15.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/site-packages (from wandb) (5.4.1)\u001b[0m\n",
      "\u001b[34mCollecting promise<3,>=2.0\n",
      "  Downloading promise-2.3.tar.gz (19 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/site-packages (from wandb) (2.8.1)\u001b[0m\n",
      "\u001b[34mCollecting subprocess32>=3.5.3\n",
      "  Downloading subprocess32-3.5.4.tar.gz (97 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.7/site-packages (from wandb) (1.15.0)\u001b[0m\n",
      "\u001b[34mCollecting Click>=7.0\n",
      "  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\u001b[0m\n",
      "\u001b[34mCollecting GitPython>=1.0.0\n",
      "  Downloading GitPython-3.1.14-py3-none-any.whl (159 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.7/site-packages (from wandb) (5.8.0)\u001b[0m\n",
      "\u001b[34mCollecting pathtools\n",
      "  Downloading pathtools-0.1.2.tar.gz (11 kB)\u001b[0m\n",
      "\u001b[34mCollecting configparser>=3.8.1\n",
      "  Downloading configparser-5.0.2-py3-none-any.whl (19 kB)\u001b[0m\n",
      "\u001b[34mCollecting docker-pycreds>=0.4.0\n",
      "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\u001b[0m\n",
      "\u001b[34mCollecting shortuuid>=0.5.0\n",
      "  Downloading shortuuid-1.0.1-py3-none-any.whl (7.5 kB)\u001b[0m\n",
      "\u001b[34mCollecting gitdb<5,>=4.0.1\n",
      "  Downloading gitdb-4.0.7-py3-none-any.whl (63 kB)\u001b[0m\n",
      "\u001b[34mCollecting smmap<5,>=3.0.1\n",
      "  Downloading smmap-4.0.0-py2.py3-none-any.whl (24 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2.10)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (3.0.4)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (1.25.11)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/site-packages (from requests<3,>=2.0.0->wandb) (2020.12.5)\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: promise, subprocess32, pathtools\n",
      "  Building wheel for promise (setup.py): started\n",
      "  Building wheel for promise (setup.py): finished with status 'done'\n",
      "  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21494 sha256=d4d096f96ae87826a034f823fbc7785092574e8fbd39e15ae8918e20795a4121\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/93/c6/762e359f8cb6a5b69c72235d798804cae523bbe41c2aa8333d\n",
      "  Building wheel for subprocess32 (setup.py): started\n",
      "  Building wheel for subprocess32 (setup.py): finished with status 'done'\n",
      "  Created wheel for subprocess32: filename=subprocess32-3.5.4-py3-none-any.whl size=6488 sha256=679ad8e3d89b8167e9270cf7da39d5ad85cf18e68ca72c19bd92dee2e7428754\n",
      "  Stored in directory: /root/.cache/pip/wheels/50/ca/fa/8fca8d246e64f19488d07567547ddec8eb084e8c0d7a59226a\n",
      "  Building wheel for pathtools (setup.py): started\u001b[0m\n",
      "\u001b[34m  Building wheel for pathtools (setup.py): finished with status 'done'\n",
      "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8784 sha256=a0cb624991a5a672dc2e3c44ab8dc77df65e7bd0b8174362ff173649d27f2387\n",
      "  Stored in directory: /root/.cache/pip/wheels/3e/31/09/fa59cef12cdcfecc627b3d24273699f390e71828921b2cbba2\u001b[0m\n",
      "\u001b[34mSuccessfully built promise subprocess32 pathtools\u001b[0m\n",
      "\u001b[34mInstalling collected packages: smmap, gitdb, subprocess32, shortuuid, sentry-sdk, promise, pathtools, GitPython, docker-pycreds, configparser, Click, wandb\u001b[0m\n",
      "\u001b[34mSuccessfully installed Click-7.1.2 GitPython-3.1.14 configparser-5.0.2 docker-pycreds-0.4.0 gitdb-4.0.7 pathtools-0.1.2 promise-2.3 sentry-sdk-1.0.0 shortuuid-1.0.1 smmap-4.0.0 subprocess32-3.5.4 wandb-0.10.25\u001b[0m\n",
      "\u001b[34mCollecting rasterio\n",
      "  Downloading rasterio-1.2.2-cp37-cp37m-manylinux1_x86_64.whl (19.1 MB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: attrs in /usr/local/lib/python3.7/site-packages (from rasterio) (20.3.0)\u001b[0m\n",
      "\u001b[34mCollecting snuggs>=1.4.1\n",
      "  Downloading snuggs-1.4.7-py3-none-any.whl (5.4 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: certifi in /usr/local/lib/python3.7/site-packages (from rasterio) (2020.12.5)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: numpy in /usr/local/lib/python3.7/site-packages (from rasterio) (1.19.5)\u001b[0m\n",
      "\u001b[34mCollecting click-plugins\n",
      "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: click<8,>=4.0 in /usr/local/lib/python3.7/site-packages (from rasterio) (7.1.2)\u001b[0m\n",
      "\u001b[34mCollecting affine\n",
      "  Downloading affine-2.3.0-py2.py3-none-any.whl (15 kB)\u001b[0m\n",
      "\u001b[34mCollecting cligj>=0.5\n",
      "  Downloading cligj-0.7.1-py3-none-any.whl (7.1 kB)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: pyparsing>=2.1.6 in /usr/local/lib/python3.7/site-packages (from snuggs>=1.4.1->rasterio) (2.4.7)\u001b[0m\n",
      "\u001b[34mInstalling collected packages: snuggs, cligj, click-plugins, affine, rasterio\u001b[0m\n",
      "\u001b[34mSuccessfully installed affine-2.3.0 click-plugins-1.1.1 cligj-0.7.1 rasterio-1.2.2 snuggs-1.4.7\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: boto3 in /usr/local/lib/python3.7/site-packages (1.17.37)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: botocore<1.21.0,>=1.20.37 in /usr/local/lib/python3.7/site-packages (from boto3) (1.20.37)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/site-packages (from boto3) (0.10.0)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/site-packages (from boto3) (0.3.6)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: urllib3<1.27,>=1.25.4 in /usr/local/lib/python3.7/site-packages (from botocore<1.21.0,>=1.20.37->boto3) (1.25.11)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/site-packages (from botocore<1.21.0,>=1.20.37->boto3) (2.8.1)\u001b[0m\n",
      "\u001b[34mRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.21.0,>=1.20.37->boto3) (1.15.0)\u001b[0m\n",
      "\u001b[34mStarting checkpoint: #015\u001b[0m\n",
      "\u001b[34mlr: 0.001, batch_size: 64, augmentation_data: False#015\u001b[0m\n",
      "\u001b[34mbands [2, 3, 4, 8, 11, 12, 18]#015\u001b[0m\n",
      "\u001b[34mInput shape: (100, 100, 7)#015\u001b[0m\n",
      "\u001b[34mISL#011#011#011#011  new_train_labels_v4.csv#015\u001b[0m\n",
      "\u001b[34mIndustrial_agriculture#011#011  new_train_labels_v5_10_percent.csv#015\u001b[0m\n",
      "\u001b[34mMining#011#011#011#011  new_train_labels_v6_half_non_isl.csv#015\u001b[0m\n",
      "\u001b[34mRoads#011#011#011#011  new_train_labels_v7_one_quarter.csv#015\u001b[0m\n",
      "\u001b[34mShifting_cultivation#011#011  new_train_labels_v8_half_nonisl_full.csv#015\u001b[0m\n",
      "\u001b[34mmisc#011#011#011#011  new_val_labels_v3.csv#015\u001b[0m\n",
      "\u001b[34mnew_test_labels_v2.csv#011#011  new_val_labels_v4.csv#015\u001b[0m\n",
      "\u001b[34mnew_test_labels_v3_one_third.csv  new_val_labels_v5_10000.csv#015\u001b[0m\n",
      "\u001b[34m0#015\u001b[0m\n",
      "\u001b[34m[2021-04-08 19:26:11.546 ip-172-31-32-18.ec2.internal:48 INFO utils.py:27] RULE_JOB_STOP_SIGNAL_FILENAME: None#015\u001b[0m\n",
      "\u001b[34m[2021-04-08 19:26:11.609 ip-172-31-32-18.ec2.internal:48 INFO profiler_config_parser.py:102] User has disabled profiler.#015\u001b[0m\n",
      "\u001b[34mDownloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5#015\u001b[0m\n",
      "\u001b[34m#015    8192/94765736 [..............................] - ETA: 1s#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#015 4202496/94765736 [>.............................] - ETA: 1s#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01514950400/94765736 [===>..........................] - ETA: 0s#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01527869184/94765736 [=======>......................] - ETA: 0s#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01540574976/94765736 [===========>..................] - ETA: 0s#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01541951232/94765736 [============>.................] - ETA: 1s#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01556614912/94765736 [================>.............] - ETA: 1s#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01573080832/94765736 [======================>.......] - ETA: 0s#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01583894272/94765736 [=========================>....] - ETA: 0s#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#010#01594773248/94765736 [==============================] - 2s 0us/step#015\u001b[0m\n",
      "\u001b[34mNo previous checkpoint found in opt/ml/checkpoints directory; start training from scratch#015\u001b[0m\n",
      "\u001b[34mtraining_dir /opt/ml/input/data/training/new_train_labels_v7_one_quarter.csv#015\u001b[0m\n",
      "\u001b[34mval_dir /opt/ml/input/data/training/new_val_labels_v3.csv#015\u001b[0m\n",
      "\u001b[34mDataloader initialization...#015\u001b[0m\n",
      "\u001b[34mlabel_file_path_train: /opt/ml/input/data/training/new_train_labels_v7_one_quarter.csv#015\u001b[0m\n",
      "\u001b[34mlabels_file_val: /opt/ml/input/data/training/new_val_labels_v3.csv#015\u001b[0m\n",
      "\u001b[34mNo data augmentation. Please set augment to True if you want to augment training dataset#015\u001b[0m\n",
      "\u001b[34mTraining on 71578 images#015\u001b[0m\n",
      "\u001b[34mValidation on 19902 images #015\u001b[0m\n",
      "\u001b[34m[2021-04-08 19:26:18.326 ip-172-31-32-18.ec2.internal:48 INFO json_config.py:91] Creating hook from json_config at /opt/ml/input/config/debughookconfig.json.#015\u001b[0m\n",
      "\u001b[34m[2021-04-08 19:26:18.328 ip-172-31-32-18.ec2.internal:48 INFO hook.py:199] tensorboard_dir has not been set for the hook. SMDebug will not be exporting tensorboard summaries.#015\u001b[0m\n",
      "\u001b[34m[2021-04-08 19:26:18.329 ip-172-31-32-18.ec2.internal:48 INFO hook.py:253] Saving to /opt/ml/output/tensors#015\u001b[0m\n",
      "\u001b[34mEpoch 1/200#015\u001b[0m\n",
      "\u001b[34m[2021-04-08 19:26:18.369 ip-172-31-32-18.ec2.internal:48 INFO hook.py:413] Monitoring the collections: sm_metrics, metrics, losses#015\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "tf_estimator.fit(efs_data_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sandbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No model found in config file.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-a3288924a242>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# model = keras.models.load_model(self.output_directory + 'best_model.hdf5', custom_objects=dependencies)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdependencies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/anaconda3/envs/canopy-ml/lib/python3.7/site-packages/tensorflow/python/keras/saving/save.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[1;32m    205\u001b[0m           (isinstance(filepath, h5py.File) or h5py.is_hdf5(filepath))):\n\u001b[1;32m    206\u001b[0m         return hdf5_format.load_model_from_hdf5(filepath, custom_objects,\n\u001b[0;32m--> 207\u001b[0;31m                                                 compile)\n\u001b[0m\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    209\u001b[0m       \u001b[0mfilepath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath_to_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/canopy-ml/lib/python3.7/site-packages/tensorflow/python/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36mload_model_from_hdf5\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'model_config'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmodel_config\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No model found in config file.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m     \u001b[0mmodel_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     model = model_config_lib.model_from_config(model_config,\n",
      "\u001b[0;31mValueError\u001b[0m: No model found in config file."
     ]
    }
   ],
   "source": [
    "from tensorflow_addons.metrics import F1Score, HammingLoss\n",
    "from tensorflow_addons.losses import SigmoidFocalCrossEntropy\n",
    "\n",
    "\n",
    "# model_path = \"/Users/zwarshavsky/Downloads/model-best.h5\"\n",
    "\n",
    "model_path = \"model_weights_RGBNIRN.h5\"\n",
    "\n",
    "dependencies = {\n",
    "    'F1Score': F1Score\n",
    "}\n",
    "\n",
    "# model = keras.models.load_model(self.output_directory + 'best_model.hdf5', custom_objects=dependencies)\n",
    "\n",
    "model = tf.keras.models.load_model(model_path, custom_objects=dependencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.engine.input_layer.InputLayer at 0x7fbaa5443c10>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fbaa5443bd0>,\n",
       " <tensorflow.python.keras.layers.convolutional.ZeroPadding2D at 0x7fbaa5443210>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fbab5494410>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fbab5494b10>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7fbab5494fd0>,\n",
       " <tensorflow.python.keras.layers.convolutional.ZeroPadding2D at 0x7fbaa5443c90>,\n",
       " <tensorflow.python.keras.layers.pooling.MaxPooling2D at 0x7fbab548d5d0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fbab548d990>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fbab548df90>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7fbab54796d0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fbab5479710>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fbab5479fd0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7fbab54725d0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fbab5472610>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fbab5472ed0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fbab5493650>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fbab5493c50>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7fbaa5443690>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7fbab546e2d0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fbab546e450>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fbab546ed50>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7fbab5493fd0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fbab54673d0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fbab5467c90>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7fbab546ee50>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fbab5484310>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fbab5484bd0>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7fbab5467fd0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7fbab547e2d0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fbab547e450>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fbab547ed10>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7fbab5484fd0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fbab549f390>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fbab549fc10>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7fbab5a5e910>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fbab548af10>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fbab548a690>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7fbab548a0d0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7fbaa6043fd0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fbaa6043f50>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fbaa6043550>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7fbab549ffd0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fbaa6055f10>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fbaa6055450>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7fbaa6043090>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fbaa6051210>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fbaa6051ad0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fbaa6055050>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fbaa6052850>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7fbaa6052dd0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7fbaa6052e90>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fbaa6051f50>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fbaa6050950>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7fbaa6050f50>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fbaa6050ed0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fbaa6047890>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7fbaa6047e90>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fbaa6047ed0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fbaa60377d0>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7fbaa6037dd0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7fbaa6037f50>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fbaa6037ed0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fbaa6034910>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7fbaa6034f10>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fbaa6034f50>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fbaa605f850>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7fbaa605fe50>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fbaa605fe90>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fbaa60595d0>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7fbaa6059250>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7fbaa6059290>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fbaa6059050>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fbaa606f610>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7fbaa606fe90>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fbaa606fe50>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fbaa6066810>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7fbaa6066e10>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fbaa6066e50>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fbaa6ebd750>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7fbaa6ebdd50>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7fbaa6ebde10>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fbaa6ebdf50>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fbaa6e978d0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7fbaa6e97ed0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fbaa6e97f10>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fbaa6ea7810>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7fbaa6ea7e10>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fbaa6ea7e50>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fbaa6e8c750>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fbaa6e8ce90>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fbaa6052f10>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7fbaa6e9da50>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7fbaa6e9db10>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fbaa6e9dc90>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fbaa6e985d0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7fbaa6e98b90>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fbaa6e98bd0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fbaa6ea84d0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7fbaa6ea8ad0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fbaa6ea8b10>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fbaa6e8f410>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7fbaa6e8fa10>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7fbaa6e8fad0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fbaa6e8fc50>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fbaa6e85590>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7fbaa6e85b90>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fbaa6e85bd0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fbaa6e8a4d0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7fbaa6e8aad0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fbaa6e8ab10>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fbaa6eb1410>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7fbaa6eb1a10>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7fbaa6eb1ad0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fbaa6eb1c50>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fbaa6ea1590>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7fbaa6e8cf90>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fbaa6ea1ad0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fbaa5ae6490>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7fbaa5ae6a90>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fbaa5ae6ad0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fbaa5ab2fd0>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7fbaa5ab2690>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7fbaa5ab2410>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fbaa5ab2290>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fbaa5ada550>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7fbaa5adab50>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fbaa5adab90>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fbaa5ae2490>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7fbaa5ae2a90>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fbaa5ae2ad0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fbaa5abcf10>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7fbaa5abcb50>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7fbaa5abc810>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fbaa5abc4d0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fbaa5aaf550>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7fbaa5aafb50>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fbaa5aafb90>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fbaa5ab8490>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7fbaa5ab8a90>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fbaa5ab8ad0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fbaa5ab13d0>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7fbaa5ab19d0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7fbaa5ab1a90>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fbaa5ab1c10>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fbaa5ac5550>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7fbaa5ac5b50>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fbaa5ac5b90>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fbaa5ae5490>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7fbaa5ae5a90>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fbaa5ae5ad0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fbab536f3d0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fbab536fb10>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fbab536ffd0>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7fbab53636d0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7fbab5363790>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fbab5363910>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fbaa5d11c90>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7fbab5370850>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fbab5370890>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fbab5363f50>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7fbab53718d0>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fbab5371bd0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fbab5371190>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7fbab53a16d0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7fbab53a1790>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fbab53a1910>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fbab5370e90>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7fbab538c850>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fbab538c890>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fbab53a1f50>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7fbab5384790>,\n",
       " <tensorflow.python.keras.layers.convolutional.Conv2D at 0x7fbab53847d0>,\n",
       " <tensorflow.python.keras.layers.normalization_v2.BatchNormalization at 0x7fbab5384f90>,\n",
       " <tensorflow.python.keras.layers.merge.Add at 0x7fbab539b6d0>,\n",
       " <tensorflow.python.keras.layers.core.Activation at 0x7fbab539b790>,\n",
       " <tensorflow.python.keras.layers.pooling.GlobalAveragePooling2D at 0x7fbab539b910>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7fbab539bdd0>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7fbab5391150>,\n",
       " <tensorflow.python.keras.layers.core.Dense at 0x7fbab5391590>]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# label_list = [\"Habitation\", \"Industrial_agriculture\", \"Mining\", \"Rainforest\", \"River\", \"Roads\", \"Savannah\", \n",
    "#               \"Shifting_cultivation\", \"Water\"]\n",
    "\n",
    "new_label_list = [\"Industrial_agriculture\",\"ISL\",\"Mining\",\"Roads\",\"Shifting_cultivation\"]\n",
    "\n",
    "# 1:\"Industrial_agriculture\"\n",
    "# 2:\"ISL\"\n",
    "# 3:\"Mining\"\n",
    "# 4:\"Roads\"\n",
    "# 5:\"Shifting_cultivation\"\n",
    "\n",
    "\n",
    "numclasses = len(new_label_list)\n",
    "bands_all = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 16, 17, 18]\n",
    "bands_RGBNIRN = [2, 3, 4, 8, 12]\n",
    "bands_RGBNIRSN = [2, 3, 4, 8, 12, 18]\n",
    "# input_shape_all_bands= (100,100,len(bands_all))\n",
    "input_shape_RGBNIRN = (100,100,len(bands_RGBNIRN))\n",
    "input_shape_all = (100,100,len(bands_all))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "\n",
    "s3 = boto3.resource('s3')\n",
    "model_url = \"https://api.wandb.ai/files/zwarshavsky/project-canopy/pc-tf-custom-container-test-job-RGBNIRN-2021-04-06-20-28-35-428-algo-1/model-best.h5\"\n",
    "checkpoint_url = \"s3://canopy-production-ml-output/ckpt/pc-tf-custom-container-test-job-RGBNIRN-2021-04-06-20-28-35-428/model_resnet_epoch_19.h5\"\n",
    "model_weights_filename = \"model_weights.h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download Model \n",
    "model_path = wget.download(model_url)\n",
    "\n",
    "#Download Weights\n",
    "KEY = \"/\".join(checkpoint_url.split(\"/\")[3:])\n",
    "s3.Bucket('canopy-production-ml-output').download_file(KEY, model_weights_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test = tf.keras.models.load_model(model_path)\n",
    "model_test.load_weights(model_weights_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "# csv_path = \"labels_test.csv\" \n",
    "# new_csv_path = \"new_test_labels_v2.csv\" \n",
    "# new_csv_path_one_third = \"new_test_labels_v3_one_third.csv\"\n",
    "train_set = \"new_train_labels_v7_one_quarter.csv\"\n",
    "test_set = \"new_test_labels_v3_one_third_uri_only.csv\"\n",
    "val_labels = \"new_val_labels_v3.csv\"\n",
    "\n",
    "# gen_all_bands = TestGenerator(label_file_path_test=test_set,\n",
    "#                               training_dir = \"./efs/\",\n",
    "#                          bucket_name='canopy-production-ml',\n",
    "#                          label_mapping_path=\"new_labels.json\",\n",
    "#                          data_extension_type='.tif',\n",
    "#                               file_mode=\"file\",\n",
    "#                          bands=bands_all,\n",
    "#                          test_data_shape=input_shape_all,\n",
    "#                          test_data_batch_size=batch_size,\n",
    "#                          enable_data_prefetch=False,\n",
    "#                          data_prefetch_size=tf.data.experimental.AUTOTUNE,\n",
    "#                          num_parallel_calls=2 * multiprocessing.cpu_count(),\n",
    "#                          output_shape=(tf.float32, tf.float32))\n",
    "\n",
    "gen_RGBNIRN = TestGenerator(label_file_path_test=test_set,\n",
    "                            training_dir = \"./efs\",\n",
    "                         bucket_name='canopy-production-ml',\n",
    "                         label_mapping_path=\"new_labels.json\",\n",
    "                         data_extension_type='.tif',\n",
    "                            file_mode=\"file\",\n",
    "                         bands=bands_RGBNIRN,\n",
    "                         test_data_shape=input_shape_RGBNIRN,\n",
    "                         test_data_batch_size=batch_size,\n",
    "                         enable_data_prefetch=False,\n",
    "                         data_prefetch_size=tf.data.experimental.AUTOTUNE,\n",
    "                         num_parallel_calls=2 * multiprocessing.cpu_count(),\n",
    "                         output_shape=(tf.float32, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_test.evaluate(gen_RGBNIRN.validation_dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-conda",
   "language": "python",
   "name": "ml-conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
